<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="http://matheus.wiki/feed.xml" rel="self" type="application/atom+xml" /><link href="http://matheus.wiki/" rel="alternate" type="text/html" /><updated>2025-11-04T19:34:17-05:00</updated><id>http://matheus.wiki/feed.xml</id><title type="html">Matheus Kunzler Maldaner</title><author><name>Matheus Kunzler Maldaner</name><email>mkunzlermaldaner@ufl.edu</email></author><entry><title type="html">Magentic-UI: Towards Human-in-the-loop Agentic Systems</title><link href="http://matheus.wiki/papers/magentic-ui" rel="alternate" type="text/html" title="Magentic-UI: Towards Human-in-the-loop Agentic Systems" /><published>2025-07-20T00:00:00-04:00</published><updated>2025-07-20T00:00:00-04:00</updated><id>http://matheus.wiki/papers/magentic-ui</id><content type="html" xml:base="http://matheus.wiki/papers/magentic-ui">&lt;p&gt;Magentic-UI is an open-source interface and architecture for studying collaborative workflows between humans and AI agents. The system supports co-planning, action approval, real-time oversight, and memory sharing across long-running web tasks. We argue that human-in-the-loop designs remain essential for deploying powerful agentic systems safely, and we showcase how Magentic-UI enables nuanced oversight and intervention across complex, multi-step scenarios.&lt;/p&gt;</content><author><name>Hussein Mozannar</name></author><summary type="html">Magentic-UI is an open-source interface and architecture for studying collaborative workflows between humans and AI agents. The system supports co-planning, action approval, real-time oversight, and memory sharing across long-running web tasks. We argue that human-in-the-loop designs remain essential for deploying powerful agentic systems safely, and we showcase how Magentic-UI enables nuanced oversight and intervention across complex, multi-step scenarios.</summary></entry><entry><title type="html">Efficient and Transparent Machine Learning: Exploring Applications of Differentiable Logic Gate Networks</title><link href="http://matheus.wiki/papers/difflogic-thesis" rel="alternate" type="text/html" title="Efficient and Transparent Machine Learning: Exploring Applications of Differentiable Logic Gate Networks" /><published>2025-05-15T00:00:00-04:00</published><updated>2025-05-15T00:00:00-04:00</updated><id>http://matheus.wiki/papers/difflogic-thesis</id><content type="html" xml:base="http://matheus.wiki/papers/difflogic-thesis">&lt;p&gt;This undergraduate thesis advances neurosymbolic AI by operationalizing Differentiable Logic Gate Networks (DiffLogic) across hardware, compression, and visualization pipelines. The work deploys DiffLogic on FPGAs for efficient inference, proposes a compression strategy that preserves decision fidelity, and delivers interpretability tooling that exposes the logical structures learned by the network. Due to an embargo, the manuscript will be released at a later date.&lt;/p&gt;</content><author><name>Matheus Kunzler Maldaner</name></author><summary type="html">This undergraduate thesis advances neurosymbolic AI by operationalizing Differentiable Logic Gate Networks (DiffLogic) across hardware, compression, and visualization pipelines. The work deploys DiffLogic on FPGAs for efficient inference, proposes a compression strategy that preserves decision fidelity, and delivers interpretability tooling that exposes the logical structures learned by the network. Due to an embargo, the manuscript will be released at a later date.</summary></entry><entry><title type="html">Seeing Twice: How Side-by-Side T2I Comparison Changes Auditing Strategies</title><link href="http://matheus.wiki/papers/seeing-twice" rel="alternate" type="text/html" title="Seeing Twice: How Side-by-Side T2I Comparison Changes Auditing Strategies" /><published>2025-05-01T00:00:00-04:00</published><updated>2025-05-01T00:00:00-04:00</updated><id>http://matheus.wiki/papers/seeing-twice</id><content type="html" xml:base="http://matheus.wiki/papers/seeing-twice">&lt;p&gt;We study auditing workflows for text-to-image systems through MIRAGE, a contrast-first interface that reveals up to four models simultaneously. In a user study with fifteen participants we observed strategies shift from single-image critiques to pattern-based reasoning once side-by-side comparison became available. Participants leveraged the multi-model view to triangulate problematic behaviors and articulate richer hypotheses about model failures.&lt;/p&gt;</content><author><name>Matheus Kunzler Maldaner</name></author><summary type="html">We study auditing workflows for text-to-image systems through MIRAGE, a contrast-first interface that reveals up to four models simultaneously. In a user study with fifteen participants we observed strategies shift from single-image critiques to pattern-based reasoning once side-by-side comparison became available. Participants leveraged the multi-model view to triangulate problematic behaviors and articulate richer hypotheses about model failures.</summary></entry><entry><title type="html">eXpLogic: Explaining Logic Types and Patterns in DiffLogic Networks</title><link href="http://matheus.wiki/papers/explogic" rel="alternate" type="text/html" title="eXpLogic: Explaining Logic Types and Patterns in DiffLogic Networks" /><published>2025-03-15T00:00:00-04:00</published><updated>2025-03-15T00:00:00-04:00</updated><id>http://matheus.wiki/papers/explogic</id><content type="html" xml:base="http://matheus.wiki/papers/explogic">&lt;p&gt;eXpLogic provides saliency explanations for DiffLogic networks by modeling how learned logic gates interact. Drawing on circuit analysis, the method traces which input patterns most influence node activations and downstream predictions. Evaluations against gradient-based explanations show that eXpLogic better anticipates score changes and enables aggressive model compression—reducing parameters by 87% and improving inference latency with minimal accuracy impact.&lt;/p&gt;</content><author><name>Stephen Wormald</name></author><summary type="html">eXpLogic provides saliency explanations for DiffLogic networks by modeling how learned logic gates interact. Drawing on circuit analysis, the method traces which input patterns most influence node activations and downstream predictions. Evaluations against gradient-based explanations show that eXpLogic better anticipates score changes and enables aggressive model compression—reducing parameters by 87% and improving inference latency with minimal accuracy impact.</summary></entry><entry><title type="html">MIRAGE: Multi-model Interface for Reviewing and Auditing Generative Text-to-Image AI</title><link href="http://matheus.wiki/papers/mirage" rel="alternate" type="text/html" title="MIRAGE: Multi-model Interface for Reviewing and Auditing Generative Text-to-Image AI" /><published>2024-11-01T00:00:00-04:00</published><updated>2024-11-01T00:00:00-04:00</updated><id>http://matheus.wiki/papers/mirage</id><content type="html" xml:base="http://matheus.wiki/papers/mirage">&lt;p&gt;MIRAGE is a web-based auditing workflow that allows participants to contrast outputs from multiple text-to-image (T2I) models on a single canvas. By centering lived experience and supporting side-by-side comparison, MIRAGE helped participants uncover subtle biases in generative models during a preliminary study. The interface offers a structured path for non-AI experts to document and submit model feedback that can inform safer, more inclusive generative AI systems.&lt;/p&gt;</content><author><name>Matheus Kunzler Maldaner</name></author><summary type="html">MIRAGE is a web-based auditing workflow that allows participants to contrast outputs from multiple text-to-image (T2I) models on a single canvas. By centering lived experience and supporting side-by-side comparison, MIRAGE helped participants uncover subtle biases in generative models during a preliminary study. The interface offers a structured path for non-AI experts to document and submit model feedback that can inform safer, more inclusive generative AI systems.</summary></entry><entry><title type="html">Abstracting General Syntax for XAI after Decomposing Explanation Sub-Components</title><link href="http://matheus.wiki/papers/abstracting-syntax" rel="alternate" type="text/html" title="Abstracting General Syntax for XAI after Decomposing Explanation Sub-Components" /><published>2024-01-01T00:00:00-05:00</published><updated>2024-01-01T00:00:00-05:00</updated><id>http://matheus.wiki/papers/abstracting-general-syntax</id><content type="html" xml:base="http://matheus.wiki/papers/abstracting-syntax">&lt;p&gt;This work introduces the Qi-Framework, a mathematically grounded syntax for describing explainability requirements across machine learning systems. By decomposing common eXplainable AI (XAI) techniques into modular sub-components, the framework standardizes how practitioners reason about their explanation needs, compare methods, and identify gaps in available tooling. The framework supports ranking XAI approaches by utility for a target use case and encourages collaborative development of interpretable AI techniques.&lt;/p&gt;</content><author><name>Stephen Wormald</name></author><summary type="html">This work introduces the Qi-Framework, a mathematically grounded syntax for describing explainability requirements across machine learning systems. By decomposing common eXplainable AI (XAI) techniques into modular sub-components, the framework standardizes how practitioners reason about their explanation needs, compare methods, and identify gaps in available tooling. The framework supports ranking XAI approaches by utility for a target use case and encourages collaborative development of interpretable AI techniques.</summary></entry></feed>